{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Lab: Quantile Regression\n",
    "\n",
    "Olivier Fercoq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preparation\n",
    "Please read the file TPquantile_regression_beginning.pdf for instructions on how to launch this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the data from txt file, the dist_data is of type spark rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = './data/ethylene_methane.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time (seconds), Methane conc (ppm), Ethylene conc (ppm), sensor readings (16 channels) ',\n",
       " '0.00    0.00    0.00    -41.98  2067.64 -37.13  2.28    8.63    -26.62  -8.46   -0.33   3437.73 2728.14 4054.03 4007.89 4478.27 5056.98 3639.09 3128.49',\n",
       " '0.01    0.00    0.00    -46.50  2067.88 -28.56  13.69   -12.35  -25.81  -5.04   -5.04   3432.44 2734.47 4038.62 4019.40 4496.72 5051.81 3636.97 3115.03',\n",
       " '0.02    0.00    0.00    -36.16  2055.81 -10.89  8.63    -2.93   -30.34  -9.27   -2.12   3438.61 2719.97 4030.92 4025.48 4489.54 5057.35 3641.81 3105.24']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_data = sc.textFile(filename)\n",
    "dist_data.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "ll = sc.parallelize([[1,1], [2,0], [3,0], [4,0]])\n",
    "def mapfunction(x):\n",
    "    print('once')\n",
    "    return x[1]\n",
    "\n",
    "ll = ll.map(mapfunction)\n",
    "print(ll.reduce(lambda x,y : x+y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter to remove the first header line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00    0.00    0.00    -41.98  2067.64 -37.13  2.28    8.63    -26.62  -8.46   -0.33   3437.73 2728.14 4054.03 4007.89 4478.27 5056.98 3639.09 3128.49'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_data = dist_data.filter(lambda line: line[0:4] != 'Time')  # remove the first line\n",
    "dist_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we removed the first line, take the first data row and turn it to float numbers by map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map handles the function for each row of rdd, lambda function turned each line to float array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist_data = dist_data.map(lambda line: np.array(list(map(float, line.split()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         -4.19800000e+01,   2.06764000e+03,  -3.71300000e+01,\n",
       "          2.28000000e+00,   8.63000000e+00,  -2.66200000e+01,\n",
       "         -8.46000000e+00,  -3.30000000e-01,   3.43773000e+03,\n",
       "          2.72814000e+03,   4.05403000e+03,   4.00789000e+03,\n",
       "          4.47827000e+03,   5.05698000e+03,   3.63909000e+03,\n",
       "          3.12849000e+03])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dist_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We take about half of the data for the training set, row[0] is the index ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_full = dist_data.filter(lambda row: row[0] < 42082.60 / 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "        -4.19800000e+01,   2.06764000e+03,  -3.71300000e+01,\n",
       "         2.28000000e+00,   8.63000000e+00,  -2.66200000e+01,\n",
       "        -8.46000000e+00,  -3.30000000e-01,   3.43773000e+03,\n",
       "         2.72814000e+03,   4.05403000e+03,   4.00789000e+03,\n",
       "         4.47827000e+03,   5.05698000e+03,   3.63909000e+03,\n",
       "         3.12849000e+03])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_full.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[8] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In order to make development smoother, we first consider 1/100th of the training data. \n",
    "# This can be changed when the algorithm is operational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[9] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_full.cache()  # Otherwise, all previous filter operations are re-run each time an action is taken.\n",
    "\n",
    "freq = 100\n",
    "#train_data = train_data_full.filter(lambda row: int(row[0]*100) % freq == 0)\n",
    "train_data = train_data_full.filter(lambda row: int(row[0]) % freq == 0)\n",
    "train_data.cache()  # Otherwise, all previous filter operations are re-run each time an action is taken.\n",
    "train_data # and it's of the same type of train_data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "        -4.19800000e+01,   2.06764000e+03,  -3.71300000e+01,\n",
       "         2.28000000e+00,   8.63000000e+00,  -2.66200000e+01,\n",
       "        -8.46000000e+00,  -3.30000000e-01,   3.43773000e+03,\n",
       "         2.72814000e+03,   4.05403000e+03,   4.00789000e+03,\n",
       "         4.47827000e+03,   5.05698000e+03,   3.63909000e+03,\n",
       "         3.12849000e+03])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for standardize both train data and train_data_full, yet collect() only the train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before centering [  0.00000000e+00   0.00000000e+00   0.00000000e+00  -4.19800000e+01\n",
      "   2.06764000e+03  -3.71300000e+01   2.28000000e+00   8.63000000e+00\n",
      "  -2.66200000e+01  -8.46000000e+00  -3.30000000e-01   3.43773000e+03\n",
      "   2.72814000e+03   4.05403000e+03   4.00789000e+03   4.47827000e+03\n",
      "   5.05698000e+03   3.63909000e+03   3.12849000e+03]\n",
      "nb of columns (19,)\n",
      "nb of observations 21102\n",
      "row_means [  1.04996516e+04   6.44759895e+01   3.86201924e+00   2.43582046e+03\n",
      "   1.76862098e+03   2.77203506e+03   3.05812133e+03   1.93607030e+03\n",
      "   2.47621240e+03   2.68626355e+03   2.98321356e+03   3.46175147e+03\n",
      "   2.76061554e+03   2.29518589e+03   2.04530061e+03   1.76770531e+03\n",
      "   1.90159642e+03   2.29297087e+03   1.85923681e+03]\n",
      "after centering [ -1.04996516e+04  -6.44759895e+01  -3.86201924e+00  -2.47780046e+03\n",
      "   2.99019024e+02  -2.80916506e+03  -3.05584133e+03  -1.92744030e+03\n",
      "  -2.50283240e+03  -2.69472355e+03  -2.98354356e+03  -2.40214743e+01\n",
      "  -3.24755360e+01   1.75884411e+03   1.96258939e+03   2.71056469e+03\n",
      "   3.15538358e+03   1.34611913e+03   1.26925319e+03]\n",
      "row_stds [  6.09131556e+03   7.83511015e+01   5.10778872e+00   2.81314101e+02\n",
      "   7.27181767e+01   1.16340280e+03   1.26901439e+03   1.14370303e+03\n",
      "   1.47540946e+03   1.12176510e+03   1.25562304e+03   2.34757501e+02\n",
      "   1.80352164e+02   9.72826407e+02   8.32084322e+02   1.02533705e+03\n",
      "   1.15040450e+03   9.57370556e+02   7.65584266e+02]\n",
      "after standardizing [-1.72370837 -0.82291108 -0.75610395 -8.80794973  4.11202587 -2.41461089\n",
      " -2.40804308 -1.68526291 -1.69636462 -2.40221731 -2.37614591 -0.10232463\n",
      " -0.18006735  1.80797324  2.35864243  2.64358408  2.74284705  1.40605862\n",
      "  1.65788829]\n",
      "this should be 0 [  6.36646291e-12  -2.26350494e-10  -2.62616595e-11   1.33411504e-10\n",
      "   8.74678108e-10   5.58202373e-11   1.83035809e-11   6.59383659e-12\n",
      "  -6.02540240e-12  -7.95807864e-12   4.17230694e-11   3.35376171e-10\n",
      "  -1.47792889e-11  -1.30739863e-11   3.41060513e-13   2.79669621e-11\n",
      "   1.25055521e-11  -2.48974175e-11   6.98037184e-11]\n",
      "this should be 1 [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.]\n",
      "before centering [  0.00000000e+00   0.00000000e+00   0.00000000e+00  -4.19800000e+01\n",
      "   2.06764000e+03  -3.71300000e+01   2.28000000e+00   8.63000000e+00\n",
      "  -2.66200000e+01  -8.46000000e+00  -3.30000000e-01   3.43773000e+03\n",
      "   2.72814000e+03   4.05403000e+03   4.00789000e+03   4.47827000e+03\n",
      "   5.05698000e+03   3.63909000e+03   3.12849000e+03]\n",
      "nb of columns (19,)\n",
      "nb of observations 2103710\n",
      "row_means [  1.05202097e+04   6.58268680e+01   4.00256815e+00   2.44494716e+03\n",
      "   1.77130464e+03   2.76510015e+03   3.05301516e+03   1.95108640e+03\n",
      "   2.49727964e+03   2.68486121e+03   2.98526551e+03   3.46079147e+03\n",
      "   2.76010957e+03   2.26482100e+03   2.02310043e+03   1.76247624e+03\n",
      "   1.89257771e+03   2.27053023e+03   1.84282247e+03]\n",
      "after centering [ -1.05202097e+04  -6.58268680e+01  -4.00256815e+00  -2.48692716e+03\n",
      "   2.96335356e+02  -2.80223015e+03  -3.05073516e+03  -1.94245640e+03\n",
      "  -2.52389964e+03  -2.69332121e+03  -2.98559551e+03  -2.30614696e+01\n",
      "  -3.19695712e+01   1.78920900e+03   1.98478957e+03   2.71579376e+03\n",
      "   3.16440229e+03   1.36855977e+03   1.28566753e+03]\n",
      "row_stds [  6.07438616e+03   7.95484604e+01   5.24099946e+00   2.31798373e+02\n",
      "   1.36465887e+02   1.11183843e+03   1.21345913e+03   1.10818080e+03\n",
      "   1.42981116e+03   1.06158547e+03   1.18945978e+03   2.37398349e+02\n",
      "   1.82950354e+02   9.36974896e+02   7.92007347e+02   9.86507646e+02\n",
      "   1.10449810e+03   9.16722868e+02   7.29246389e+02]\n",
      "after standardizing [ -1.73189676  -0.8275065   -0.76370322 -10.72883786   2.17149767\n",
      "  -2.52035734  -2.51408151  -1.75283348  -1.76519789  -2.5370743\n",
      "  -2.51004325  -0.0971425   -0.17474452   1.90955917   2.50602419\n",
      "   2.75293736   2.86501378   1.49288277   1.76300843]\n",
      "this should be 0 [  1.41444616e-08  -1.02130434e-06   3.36374796e-07  -8.91814125e-07\n",
      "  -1.12510497e-06   1.42914359e-07   1.15091098e-07   2.42464012e-07\n",
      "   7.88277248e-08   2.44879629e-07   2.39844667e-07   8.07762262e-07\n",
      "   1.95246139e-06   2.04890966e-08   1.91954314e-07   1.27736712e-07\n",
      "   1.57495379e-07  -4.32191882e-09   2.09096470e-07]\n",
      "this should be 1 [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.]\n"
     ]
    }
   ],
   "source": [
    "def standardize(train_data):\n",
    "    print('before centering', train_data.first())\n",
    "    row_sums = train_data.reduce(lambda a, b: a + b)\n",
    "    print('nb of columns', row_sums.shape)\n",
    "    n_train = train_data.count()\n",
    "    print('nb of observations', n_train)\n",
    "\n",
    "    row_means = row_sums / n_train\n",
    "    print('row_means', row_means)\n",
    "\n",
    "    train_data = train_data.map(lambda r: r - row_means)\n",
    "    print('after centering', train_data.first())\n",
    "\n",
    "    row_stds = np.sqrt(train_data.map(lambda r: r ** 2).reduce(lambda a, b: a + b) / n_train)\n",
    "    print('row_stds', row_stds)\n",
    "    train_data = train_data.map(lambda r: r / row_stds)\n",
    "    print('after standardizing', train_data.first())\n",
    "\n",
    "    row_sums_should_be_0 = train_data.reduce(lambda a, b: a + b)\n",
    "    print('this should be 0', row_sums_should_be_0)\n",
    "    row_stds_should_be_1 = np.sqrt(train_data.map(lambda r: r ** 2).reduce(lambda a, b: a + b) / n_train)\n",
    "    print('this should be 1', row_stds_should_be_1)\n",
    "\n",
    "    return train_data\n",
    "\n",
    "train_data = standardize(train_data)\n",
    "train_data_NotDistributed = np.array(train_data.collect())  # collect() should be used only on small RDDs\n",
    "\n",
    "train_data_full = standardize(train_data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21102, 19)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PythonRDD[19] at collect at <ipython-input-22-4759d30af17f>:27,\n",
       " PythonRDD[28] at RDD at PythonRDD.scala:48)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data_NotDistributed.shape)\n",
    "train_data, train_data_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21102, 16), (21102, 2))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data_NotDistributed[:, 3:]\n",
    "y = train_data_NotDistributed[:, 1:3]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get closed-form solution\n",
    "W = np.linalg.solve(a=X.T.dot(X), b=X.T.dot(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 2), array([[  0.20112332,   0.40003616],\n",
       "        [  0.07544213,   0.07243659],\n",
       "        [  6.80878733,  -1.50964233],\n",
       "        [ -3.69864834,   6.17855383],\n",
       "        [-10.68830581,  -1.12443226],\n",
       "        [  3.74523502,  -1.53292001],\n",
       "        [  0.60163843,  -6.83221707],\n",
       "        [  2.867276  ,   3.19708374],\n",
       "        [ -1.31779565,   0.45799037],\n",
       "        [  1.07483576,  -0.87620455],\n",
       "        [  1.64402582,  -1.17964847],\n",
       "        [ -7.05906705,  -7.37769584],\n",
       "        [  2.30394624,   1.89215007],\n",
       "        [  5.1616917 ,   0.78613241],\n",
       "        [  2.57448691,   5.48816121],\n",
       "        [ -3.3299369 ,   2.8900424 ]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on the reduced set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parallel_train_X = sc.parallelize(train_data_NotDistributed) # or use directly the train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX = parallel_train_X.map(lambda a: np.outer(a[3:], a[3:])).reduce(lambda a,b: a+b)\n",
    "yy = parallel_train_X.map(lambda a: np.outer(a[3:], a[1:3])).reduce(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 16), (16, 2))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.shape, yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = np.linalg.inv(XX).dot(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.20112332,   0.40003616],\n",
       "       [  0.07544213,   0.07243659],\n",
       "       [  6.80878733,  -1.50964233],\n",
       "       [ -3.69864834,   6.17855383],\n",
       "       [-10.68830581,  -1.12443226],\n",
       "       [  3.74523502,  -1.53292001],\n",
       "       [  0.60163843,  -6.83221707],\n",
       "       [  2.867276  ,   3.19708374],\n",
       "       [ -1.31779565,   0.45799037],\n",
       "       [  1.07483576,  -0.87620455],\n",
       "       [  1.64402582,  -1.17964847],\n",
       "       [ -7.05906705,  -7.37769584],\n",
       "       [  2.30394624,   1.89215007],\n",
       "       [  5.1616917 ,   0.78613241],\n",
       "       [  2.57448691,   5.48816121],\n",
       "       [ -3.3299369 ,   2.8900424 ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.20112332,   0.40003616],\n",
       "       [  0.07544213,   0.07243659],\n",
       "       [  6.80878733,  -1.50964233],\n",
       "       [ -3.69864834,   6.17855383],\n",
       "       [-10.68830581,  -1.12443226],\n",
       "       [  3.74523502,  -1.53292001],\n",
       "       [  0.60163843,  -6.83221707],\n",
       "       [  2.867276  ,   3.19708374],\n",
       "       [ -1.31779565,   0.45799037],\n",
       "       [  1.07483576,  -0.87620455],\n",
       "       [  1.64402582,  -1.17964847],\n",
       "       [ -7.05906705,  -7.37769584],\n",
       "       [  2.30394624,   1.89215007],\n",
       "       [  5.1616917 ,   0.78613241],\n",
       "       [  2.57448691,   5.48816121],\n",
       "       [ -3.3299369 ,   2.8900424 ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def solve_linear_parallel(rrd_train):\n",
    "    XX = rrd_train.map(lambda a: np.outer(a[3:], a[3:])).reduce(lambda a,b: a+b)\n",
    "    yy = rrd_train.map(lambda a: np.outer(a[3:], a[1:3])).reduce(lambda a,b: a+b)\n",
    "    W = np.linalg.inv(XX).dot(yy)\n",
    "    return W\n",
    "\n",
    "solve_linear_parallel(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on the full set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09682988,  0.0485206 ],\n",
       "       [ 0.01240669, -0.01502376],\n",
       "       [-0.14024083,  5.88192701],\n",
       "       [ 0.34187629, -3.28065969],\n",
       "       [-6.83667423,  2.31979054],\n",
       "       [ 4.59287714, -1.15516419],\n",
       "       [ 0.99581238, -5.54778859],\n",
       "       [ 1.39054027,  1.35446226],\n",
       "       [-0.867363  ,  0.33945828],\n",
       "       [ 0.69831324, -0.46888552],\n",
       "       [ 1.81161887, -2.64645593],\n",
       "       [-3.18783061, -1.90203955],\n",
       "       [ 0.22809633, -0.40600687],\n",
       "       [ 2.78471187, -0.491782  ],\n",
       "       [ 0.08956648,  4.89059757],\n",
       "       [-1.11281948,  1.72824999]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_linear_parallel(train_data_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.25  3.25  5.5 ]\n",
      "[[ 2.25  3.25  5.5 ]\n",
      " [ 2.5   2.5   5.5 ]]\n",
      "[[ 1.8    3.6    5.4  ]\n",
      " [ 2.025  2.925  4.95 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# this calculate the proximal of pinball funciton \n",
    "# L_tao(y - v), where L_tao(v) = max(−(1 − τ)v, τv)\n",
    "def func_pinball(v, tao=0.9):\n",
    "    return np.maximum(-(1-tao)*v, tao*v)\n",
    "\n",
    "def prox_pinball(v, y, tao=0.9, s=1):\n",
    "    \n",
    "    length = len(v)\n",
    "    w = np.zeros(length)\n",
    "    \n",
    "    for i in range(length):\n",
    "        if v[i] > y[i] + (1 - tao)*s:\n",
    "            w[i] = v[i] + (tao - 1) * s\n",
    "        elif v[i] < y[i] - tao*s:\n",
    "            w[i] = v[i] + tao * s\n",
    "        else:\n",
    "            w[i] = y[i]\n",
    "    return w\n",
    "\n",
    "def func_pinball_multi_labels(v, tao=0.9):\n",
    "    if len(v.shape) == 1:\n",
    "        return func_pinball(v, tao)\n",
    "    return np.c_[[func_pinball(v[:,i], tao) for i in range(v.shape[1])]].T\n",
    "\n",
    "\n",
    "def prox_pinball_multi_labels(v, y, tao=0.9, s=1):\n",
    "    if len(v.shape) == 1:\n",
    "        return prox_pinball(v, y, tao, s)\n",
    "    return np.c_[[prox_pinball(v[:,i], y[:,i], tao, s) for i in range(v.shape[1])]].T\n",
    "    \n",
    "# test\n",
    "v = np.array([2, 4, 6])\n",
    "y = np.array([3.9, 1, 5.5])\n",
    "tao = 0.25\n",
    "print(prox_pinball(v, y, tao))\n",
    "\n",
    "vm = array([[ 2,  4,  6 ], [ 2.25,  3.25,  5.5 ]])\n",
    "ym = np.array([[3.9, 1, 5.5], [3.9, 1, 5.5]])\n",
    "print(prox_pinball_multi_labels(vm, ym, tao))\n",
    "print(func_pinball_multi_labels(vm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21102, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_data_NotDistributed[:, 1:3]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### not distributed admm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def derivative_f(alpha, d):\n",
    "    A = np.diag([alpha]*(d-1) + [0])\n",
    "    return A\n",
    "\n",
    "def func_f(alpha, x):\n",
    "    return alpha/2 * np.sum(x**2)\n",
    "    \n",
    "def admm_serial(M, y, f, df, g, prox_g, z0, p0, alpha=1, gamma=1, tao=0.9, run_max=100, verbose=False, call_back=None, **params):\n",
    "    d = M.shape[1]\n",
    "    if len(y.shape) == 1:\n",
    "        x = np.zeros(d)\n",
    "    else:\n",
    "        x = np.zeros((d, y.shape[1]))\n",
    "    z = z0.copy()\n",
    "    p = p0.copy()\n",
    "    \n",
    "    for i in range(run_max):\n",
    "\n",
    "        x_old = x.copy()\n",
    "        p_old = p.copy()\n",
    "        \n",
    "        # step 1 calculate the xk+1\n",
    "        A1 = 1/gamma*M.T.dot(M) + df(alpha, d)\n",
    "        b1 = 1/gamma*M.T.dot(z) - M.T.dot(p)\n",
    "        x = np.linalg.inv(A1).dot(b1)\n",
    "        # step 2 calculate the zk+1\n",
    "        v = gamma*(p + 1/gamma*M.dot(x))\n",
    "        z = prox_g(v, y, tao, gamma) # s = gamma ?\n",
    "        # step 3 calculate the p\n",
    "        #print(z.shape)\n",
    "        p = p + 1/gamma*(M.dot(x) - z)\n",
    "\n",
    "        obj_func = f(alpha, x) + np.sum(g(y - M.dot(x), tao))\n",
    "        # a call back function for user \n",
    "        call_values = {'x':x.copy(), 'z':z.copy(), 'p': p.copy(), 'obj':obj_func}\n",
    "        call_back(call_values, **params)\n",
    "        \n",
    "        # calculate the distance to stop admm\n",
    "        dis = np.linalg.norm(x-x_old)+np.linalg.norm(p - p_old)\n",
    "        if verbose:\n",
    "            print(\"run time =\", i, \"the value of object function is,\", obj_func, \"distance is\", dis)\n",
    "            \n",
    "        if dis < 1e-3:\n",
    "            print(\"executed\", i, \" times x=\", x)\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time \n",
    "# train_data_NotDistributed is the trainign data set \n",
    "n_obs, n_features = train_data_NotDistributed.shape\n",
    "M = np.c_[train_data_NotDistributed[:, 3:], np.array([1]*n_obs)]\n",
    "#y = train_data_NotDistributed[:, 2]\n",
    "y = train_data_NotDistributed[:, 1:3]\n",
    "f = func_f\n",
    "df = derivative_f\n",
    "g = func_pinball_multi_labels\n",
    "prox_g = prox_pinball_multi_labels\n",
    "z0 = np.zeros((n_obs,2))\n",
    "p0 = np.zeros((n_obs,2))\n",
    "\n",
    "history = {st: [] for st in ['obj', 'x', 'p', 'z']}\n",
    "def callback(values, history):\n",
    "    history['obj'].append(values['obj'])\n",
    "    history['x'].append(values['x'])\n",
    "    history['p'].append(values['p'])\n",
    "    history['z'].append(values['z'])\n",
    "\n",
    "# we show that the distance (x, p) can be smaller than 1e-3\n",
    "t1 = time.time()\n",
    "admm_serial(M, y, f, df, g, prox_g, z0, p0, alpha=1, gamma=1, tao=0.9, run_max=100, verbose=False, call_back=callback, history=history)\n",
    "t2 = time.time()\n",
    "t_serial = t2 - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime : 5.188315 s\n"
     ]
    }
   ],
   "source": [
    "print('runtime : %f s'%t_serial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = len(history['z'])\n",
    "history['Mw'] = list(map(lambda x: M.dot(x), history['x']))\n",
    "history['|Mw-z|'] = [np.linalg.norm(history['Mw'][i] - history['z'][i]) for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x124f05470>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAFNCAYAAAC0ZpNRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLyRemAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1181784a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(history['|Mw-z|'])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('|Mw-z|')\n",
    "plt.title('serial admm')\n",
    "plt.subplot(122)\n",
    "plt.plot(history['obj'])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('objective')\n",
    "plt.title('serial admm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "### try a parallel one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implement a parallel implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# distributed one, use train_data rrd\n",
    "from pyspark import StorageLevel\n",
    "\n",
    "def admm_dist(train_data, n_class, f, df, g, prox_g, alpha=1, gamma=1, tao=0.9, run_max=100, verbose=False, call_back=None, **params):\n",
    "    \n",
    "    d = len(train_data.first()[3:]) + 1\n",
    "    \n",
    "    if n_class == 1:\n",
    "        w = np.zeros(d)\n",
    "    else:\n",
    "        w = np.zeros((d, n_class))\n",
    "\n",
    "    train_data_ = train_data.map(lambda row: { 'y' : row[1:1+n_class],\n",
    "                                           'x' : np.concatenate([row[1+n_class:], [1]]),\n",
    "                                           'z' : np.zeros(n_class),\n",
    "                                           'mu' : np.zeros(n_class)\n",
    "                                      })\n",
    "    #train_data_.cache()\n",
    "    train_data_.persist(storageLevel=StorageLevel(True, True, False, False, 1))\n",
    "    \n",
    "    A1 = train_data_.map(lambda x: 1/gamma*np.outer(x['x'], x['x'])).reduce(lambda x, y: x+y) \n",
    "    A1 += df(alpha, d)\n",
    "    inv_A1 = np.linalg.inv(A1)\n",
    "    \n",
    "    objs = []\n",
    "    errs = []\n",
    "    for i in range(run_max):\n",
    "        w_old = w.copy()\n",
    "        \n",
    "        # step 1 calculate the x_k+1\n",
    "        start = time.time()\n",
    "        train_data_.persist(storageLevel=StorageLevel(True, True, False, False, 1))\n",
    "        \n",
    "        b1 = train_data_.map(lambda x: 1/gamma*np.outer(x['x'], x['z']-x['mu'])).reduce(lambda x, y: x+y)\n",
    "        w = inv_A1.dot(b1)\n",
    "        \n",
    "        print(\"time used for calculate w is\", time.time() - start)\n",
    "        \n",
    "        train_data_ = train_data_.map(lambda row: { \n",
    "                                'y' : row['y'],\n",
    "                                'x' : row['x'],\n",
    "                                'z' : prox_g(gamma * row['mu'] + row['x'].dot(w), row['y'], tao, gamma),\n",
    "                                'mu' : row['mu']\n",
    "                                    })\n",
    "        \n",
    "        train_data_ = train_data_.map(lambda row: { \n",
    "                                'y' : row['y'],\n",
    "                                'x' : row['x'],\n",
    "                                'z' : row['z'],\n",
    "                                'mu' : row['mu'] + 1./gamma*(row['x'].dot(w)- row['z'])\n",
    "                                    })\n",
    "        #train_data_.cache()\n",
    "        \n",
    "        obj_func = f(alpha, w)+train_data_.map(lambda x: np.sum(g(x['y']-x['x'].dot(w),tao))).reduce(lambda x,y: x+y)\n",
    "        \n",
    "        dis = np.linalg.norm(w-w_old)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"run time =\", i, \"the value of object function is,\", obj_func, \"distance is\", dis)\n",
    "            \n",
    "        objs.append(obj_func)\n",
    "        errs.append(dis)\n",
    "        \n",
    "    return train_data_, objs, w\n",
    "\n",
    "f = func_f\n",
    "df = derivative_f\n",
    "g = func_pinball\n",
    "prox_g = prox_pinball\n",
    "n_class = 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[19] at collect at <ipython-input-22-4759d30af17f>:27"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used for calculate w is 0.5089519023895264\n",
      "run time = 0 the value of object function is, 18341.830288 distance is 0.0\n",
      "time used for calculate w is 1.0538220405578613\n",
      "run time = 1 the value of object function is, 7300.11834515 distance is 14.6798235069\n",
      "time used for calculate w is 0.9242241382598877\n",
      "run time = 2 the value of object function is, 6066.37522829 distance is 9.10917602388\n",
      "time used for calculate w is 0.8743269443511963\n",
      "run time = 3 the value of object function is, 5575.31332409 distance is 4.65981562986\n",
      "time used for calculate w is 0.9308807849884033\n",
      "run time = 4 the value of object function is, 5387.94253495 distance is 2.38975394459\n",
      "time used for calculate w is 1.1577470302581787\n",
      "run time = 5 the value of object function is, 5276.14012032 distance is 1.35129930914\n",
      "time used for calculate w is 2.3626272678375244\n",
      "run time = 6 the value of object function is, 5229.16925573 distance is 1.22148187668\n",
      "time used for calculate w is 2.9008140563964844\n",
      "run time = 7 the value of object function is, 5197.51759163 distance is 1.40010228765\n",
      "time used for calculate w is 2.3538670539855957\n",
      "run time = 8 the value of object function is, 5165.61538754 distance is 1.33614352167\n",
      "time used for calculate w is 1.8977198600769043\n",
      "run time = 9 the value of object function is, 5138.81081259 distance is 1.11219668959\n",
      "time used for calculate w is 0.9075992107391357\n",
      "run time = 10 the value of object function is, 5121.41828458 distance is 0.9499954738\n",
      "time used for calculate w is 0.8419022560119629\n",
      "run time = 11 the value of object function is, 5109.75962319 distance is 0.830822105914\n",
      "time used for calculate w is 0.8528220653533936\n",
      "run time = 12 the value of object function is, 5101.76352562 distance is 0.756641272388\n",
      "time used for calculate w is 0.8796746730804443\n",
      "run time = 13 the value of object function is, 5094.24530534 distance is 0.699856130497\n",
      "time used for calculate w is 0.856816291809082\n",
      "run time = 14 the value of object function is, 5086.51479916 distance is 0.661543211911\n",
      "time used for calculate w is 0.8481132984161377\n",
      "run time = 15 the value of object function is, 5080.69614221 distance is 0.597644069872\n",
      "time used for calculate w is 0.9385049343109131\n",
      "run time = 16 the value of object function is, 5076.37294242 distance is 0.533755422452\n",
      "time used for calculate w is 0.8864099979400635\n",
      "run time = 17 the value of object function is, 5073.19726982 distance is 0.456930331508\n",
      "time used for calculate w is 0.991265058517456\n",
      "run time = 18 the value of object function is, 5070.58981772 distance is 0.38299830051\n",
      "time used for calculate w is 0.9103958606719971\n",
      "run time = 19 the value of object function is, 5068.04616063 distance is 0.318366371132\n",
      "runtime: 40.898969 s\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "td_dist, objs_dist, w_dist = admm_dist(train_data, n_class, \n",
    "                                       f, df, g, prox_g, \n",
    "                                       alpha=1, gamma=1, tao=0.9, \n",
    "                                       run_max=20, verbose=True)        \n",
    "t2 = time.time()\n",
    "t_dist = t2 - t1\n",
    "print('runtime: %f s'%t_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1168f99e8>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAAFNCAYAAAB45RYOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1166b4ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(objs_dist)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('objective')\n",
    "plt.title('dist admm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## the large data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.treeReduce??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used for calculate w is 19.501004934310913\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "td_dist_full, objs_dist_full, w_dist_full = admm_dist(train_data_full, n_class, \n",
    "                                       f, df, g, prox_g, \n",
    "                                       alpha=1, gamma=1, tao=0.9, \n",
    "                                       run_max=20, verbose=True)        \n",
    "t2 = time.time()\n",
    "t_dist = t2 - t1\n",
    "print('runtime: %f s'%t_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
