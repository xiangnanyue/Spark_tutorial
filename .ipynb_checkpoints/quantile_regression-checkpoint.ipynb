{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Lab: Quantile Regression\n",
    "\n",
    "Olivier Fercoq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preparation\n",
    "Please read the file TPquantile_regression_beginning.pdf for instructions on how to launch this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the data from txt file, the dist_data is of type spark rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = './data/ethylene_methane.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time (seconds), Methane conc (ppm), Ethylene conc (ppm), sensor readings (16 channels) ',\n",
       " '0.00    0.00    0.00    -41.98  2067.64 -37.13  2.28    8.63    -26.62  -8.46   -0.33   3437.73 2728.14 4054.03 4007.89 4478.27 5056.98 3639.09 3128.49',\n",
       " '0.01    0.00    0.00    -46.50  2067.88 -28.56  13.69   -12.35  -25.81  -5.04   -5.04   3432.44 2734.47 4038.62 4019.40 4496.72 5051.81 3636.97 3115.03',\n",
       " '0.02    0.00    0.00    -36.16  2055.81 -10.89  8.63    -2.93   -30.34  -9.27   -2.12   3438.61 2719.97 4030.92 4025.48 4489.54 5057.35 3641.81 3105.24']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_data = sc.textFile(filename)\n",
    "dist_data.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter to remove the first header line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00    0.00    0.00    -41.98  2067.64 -37.13  2.28    8.63    -26.62  -8.46   -0.33   3437.73 2728.14 4054.03 4007.89 4478.27 5056.98 3639.09 3128.49'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_data = dist_data.filter(lambda line: line[0:4] != 'Time')  # remove the first line\n",
    "dist_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we removed the first line, take the first data row and turn it to float numbers by map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "        -4.19800000e+01,   2.06764000e+03,  -3.71300000e+01,\n",
       "         2.28000000e+00,   8.63000000e+00,  -2.66200000e+01,\n",
       "        -8.46000000e+00,  -3.30000000e-01,   3.43773000e+03,\n",
       "         2.72814000e+03,   4.05403000e+03,   4.00789000e+03,\n",
       "         4.47827000e+03,   5.05698000e+03,   3.63909000e+03,\n",
       "         3.12849000e+03])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = dist_data.first()\n",
    "#print(s)\n",
    "a = np.array(list(map(float, s.split())))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map handles the function for each row of rdd, lambda function turned each line to float array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist_data = dist_data.map(lambda line: np.array(list(map(float, line.split()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "        -4.19800000e+01,   2.06764000e+03,  -3.71300000e+01,\n",
       "         2.28000000e+00,   8.63000000e+00,  -2.66200000e+01,\n",
       "        -8.46000000e+00,  -3.30000000e-01,   3.43773000e+03,\n",
       "         2.72814000e+03,   4.05403000e+03,   4.00789000e+03,\n",
       "         4.47827000e+03,   5.05698000e+03,   3.63909000e+03,\n",
       "         3.12849000e+03])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We take about half of the data for the training set, row[0] is the index ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_full = dist_data.filter(lambda row: row[0] < 42082.60 / 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "        -4.19800000e+01,   2.06764000e+03,  -3.71300000e+01,\n",
       "         2.28000000e+00,   8.63000000e+00,  -2.66200000e+01,\n",
       "        -8.46000000e+00,  -3.30000000e-01,   3.43773000e+03,\n",
       "         2.72814000e+03,   4.05403000e+03,   4.00789000e+03,\n",
       "         4.47827000e+03,   5.05698000e+03,   3.63909000e+03,\n",
       "         3.12849000e+03])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_full.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In order to make development smoother, we first consider 1/100th of the training data. \n",
    "# This can be changed when the algorithm is operational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[9] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_full.cache()  # Otherwise, all previous filter operations are re-run each time an action is taken.\n",
    "\n",
    "freq = 100\n",
    "#train_data = train_data_full.filter(lambda row: int(row[0]*100) % freq == 0)\n",
    "train_data = train_data_full.filter(lambda row: int(row[0]) % freq == 0)\n",
    "train_data.cache()  # Otherwise, all previous filter operations are re-run each time an action is taken.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "        -4.19800000e+01,   2.06764000e+03,  -3.71300000e+01,\n",
       "         2.28000000e+00,   8.63000000e+00,  -2.66200000e+01,\n",
       "        -8.46000000e+00,  -3.30000000e-01,   3.43773000e+03,\n",
       "         2.72814000e+03,   4.05403000e+03,   4.00789000e+03,\n",
       "         4.47827000e+03,   5.05698000e+03,   3.63909000e+03,\n",
       "         3.12849000e+03])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for standardize both train data and train_data_full, yet collect() only the train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before centering [  0.00000000e+00   0.00000000e+00   0.00000000e+00  -4.19800000e+01\n",
      "   2.06764000e+03  -3.71300000e+01   2.28000000e+00   8.63000000e+00\n",
      "  -2.66200000e+01  -8.46000000e+00  -3.30000000e-01   3.43773000e+03\n",
      "   2.72814000e+03   4.05403000e+03   4.00789000e+03   4.47827000e+03\n",
      "   5.05698000e+03   3.63909000e+03   3.12849000e+03]\n",
      "nb of columns (19,)\n",
      "nb of observations 21102\n",
      "row_means [  1.04996516e+04   6.44759895e+01   3.86201924e+00   2.43582046e+03\n",
      "   1.76862098e+03   2.77203506e+03   3.05812133e+03   1.93607030e+03\n",
      "   2.47621240e+03   2.68626355e+03   2.98321356e+03   3.46175147e+03\n",
      "   2.76061554e+03   2.29518589e+03   2.04530061e+03   1.76770531e+03\n",
      "   1.90159642e+03   2.29297087e+03   1.85923681e+03]\n",
      "after centering [ -1.04996516e+04  -6.44759895e+01  -3.86201924e+00  -2.47780046e+03\n",
      "   2.99019024e+02  -2.80916506e+03  -3.05584133e+03  -1.92744030e+03\n",
      "  -2.50283240e+03  -2.69472355e+03  -2.98354356e+03  -2.40214743e+01\n",
      "  -3.24755360e+01   1.75884411e+03   1.96258939e+03   2.71056469e+03\n",
      "   3.15538358e+03   1.34611913e+03   1.26925319e+03]\n",
      "row_stds [  6.09131556e+03   7.83511015e+01   5.10778872e+00   2.81314101e+02\n",
      "   7.27181767e+01   1.16340280e+03   1.26901439e+03   1.14370303e+03\n",
      "   1.47540946e+03   1.12176510e+03   1.25562304e+03   2.34757501e+02\n",
      "   1.80352164e+02   9.72826407e+02   8.32084322e+02   1.02533705e+03\n",
      "   1.15040450e+03   9.57370556e+02   7.65584266e+02]\n",
      "after standardizing [-1.72370837 -0.82291108 -0.75610395 -8.80794973  4.11202587 -2.41461089\n",
      " -2.40804308 -1.68526291 -1.69636462 -2.40221731 -2.37614591 -0.10232463\n",
      " -0.18006735  1.80797324  2.35864243  2.64358408  2.74284705  1.40605862\n",
      "  1.65788829]\n",
      "this should be 0 [  6.36646291e-12  -2.26350494e-10  -2.62616595e-11   1.33411504e-10\n",
      "   8.74678108e-10   5.58202373e-11   1.83035809e-11   6.59383659e-12\n",
      "  -6.02540240e-12  -7.95807864e-12   4.17230694e-11   3.35376171e-10\n",
      "  -1.47792889e-11  -1.30739863e-11   3.41060513e-13   2.79669621e-11\n",
      "   1.25055521e-11  -2.48974175e-11   6.98037184e-11]\n",
      "this should be 1 [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.]\n",
      "before centering [  0.00000000e+00   0.00000000e+00   0.00000000e+00  -4.19800000e+01\n",
      "   2.06764000e+03  -3.71300000e+01   2.28000000e+00   8.63000000e+00\n",
      "  -2.66200000e+01  -8.46000000e+00  -3.30000000e-01   3.43773000e+03\n",
      "   2.72814000e+03   4.05403000e+03   4.00789000e+03   4.47827000e+03\n",
      "   5.05698000e+03   3.63909000e+03   3.12849000e+03]\n",
      "nb of columns (19,)\n",
      "nb of observations 2103710\n",
      "row_means [  1.05202097e+04   6.58268680e+01   4.00256815e+00   2.44494716e+03\n",
      "   1.77130464e+03   2.76510015e+03   3.05301516e+03   1.95108640e+03\n",
      "   2.49727964e+03   2.68486121e+03   2.98526551e+03   3.46079147e+03\n",
      "   2.76010957e+03   2.26482100e+03   2.02310043e+03   1.76247624e+03\n",
      "   1.89257771e+03   2.27053023e+03   1.84282247e+03]\n",
      "after centering [ -1.05202097e+04  -6.58268680e+01  -4.00256815e+00  -2.48692716e+03\n",
      "   2.96335356e+02  -2.80223015e+03  -3.05073516e+03  -1.94245640e+03\n",
      "  -2.52389964e+03  -2.69332121e+03  -2.98559551e+03  -2.30614696e+01\n",
      "  -3.19695712e+01   1.78920900e+03   1.98478957e+03   2.71579376e+03\n",
      "   3.16440229e+03   1.36855977e+03   1.28566753e+03]\n",
      "row_stds [  6.07438616e+03   7.95484604e+01   5.24099946e+00   2.31798373e+02\n",
      "   1.36465887e+02   1.11183843e+03   1.21345913e+03   1.10818080e+03\n",
      "   1.42981116e+03   1.06158547e+03   1.18945978e+03   2.37398349e+02\n",
      "   1.82950354e+02   9.36974896e+02   7.92007347e+02   9.86507646e+02\n",
      "   1.10449810e+03   9.16722868e+02   7.29246389e+02]\n",
      "after standardizing [ -1.73189676  -0.8275065   -0.76370322 -10.72883786   2.17149767\n",
      "  -2.52035734  -2.51408151  -1.75283348  -1.76519789  -2.5370743\n",
      "  -2.51004325  -0.0971425   -0.17474452   1.90955917   2.50602419\n",
      "   2.75293736   2.86501378   1.49288277   1.76300843]\n",
      "this should be 0 [  1.41444616e-08  -1.02130434e-06   3.36374796e-07  -8.91814125e-07\n",
      "  -1.12510497e-06   1.42914359e-07   1.15091098e-07   2.42464012e-07\n",
      "   7.88277248e-08   2.44879629e-07   2.39844667e-07   8.07762262e-07\n",
      "   1.95246139e-06   2.04890966e-08   1.91954314e-07   1.27736712e-07\n",
      "   1.57495379e-07  -4.32191882e-09   2.09096470e-07]\n",
      "this should be 1 [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.]\n"
     ]
    }
   ],
   "source": [
    "def standardize(train_data):\n",
    "    print('before centering', train_data.first())\n",
    "    row_sums = train_data.reduce(lambda a, b: a + b)\n",
    "    print('nb of columns', row_sums.shape)\n",
    "    n_train = train_data.count()\n",
    "    print('nb of observations', n_train)\n",
    "\n",
    "    row_means = row_sums / n_train\n",
    "    print('row_means', row_means)\n",
    "\n",
    "    train_data = train_data.map(lambda r: r - row_means)\n",
    "    print('after centering', train_data.first())\n",
    "\n",
    "    row_stds = np.sqrt(train_data.map(lambda r: r ** 2).reduce(lambda a, b: a + b) / n_train)\n",
    "    print('row_stds', row_stds)\n",
    "    train_data = train_data.map(lambda r: r / row_stds)\n",
    "    print('after standardizing', train_data.first())\n",
    "\n",
    "    row_sums_should_be_0 = train_data.reduce(lambda a, b: a + b)\n",
    "    print('this should be 0', row_sums_should_be_0)\n",
    "    row_stds_should_be_1 = np.sqrt(train_data.map(lambda r: r ** 2).reduce(lambda a, b: a + b) / n_train)\n",
    "    print('this should be 1', row_stds_should_be_1)\n",
    "\n",
    "    return train_data\n",
    "\n",
    "train_data = standardize(train_data)\n",
    "train_data_NotDistributed = np.array(train_data.collect())  # collect() should be used only on small RDDs\n",
    "\n",
    "train_data_full = standardize(train_data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21102, 19), PythonRDD[19] at collect at <ipython-input-21-4759d30af17f>:27)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_NotDistributed.shape, train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21102, 16), (21102, 2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data_NotDistributed[:, 3:]\n",
    "y = train_data_NotDistributed[:, 1:3]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get closed-form solution\n",
    "W = np.linalg.solve(a=X.T.dot(X), b=X.T.dot(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 2), array([[  0.20112332,   0.40003616],\n",
       "        [  0.07544213,   0.07243659],\n",
       "        [  6.80878733,  -1.50964233],\n",
       "        [ -3.69864834,   6.17855383],\n",
       "        [-10.68830581,  -1.12443226],\n",
       "        [  3.74523502,  -1.53292001],\n",
       "        [  0.60163843,  -6.83221707],\n",
       "        [  2.867276  ,   3.19708374],\n",
       "        [ -1.31779565,   0.45799037],\n",
       "        [  1.07483576,  -0.87620455],\n",
       "        [  1.64402582,  -1.17964847],\n",
       "        [ -7.05906705,  -7.37769584],\n",
       "        [  2.30394624,   1.89215007],\n",
       "        [  5.1616917 ,   0.78613241],\n",
       "        [  2.57448691,   5.48816121],\n",
       "        [ -3.3299369 ,   2.8900424 ]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on the reduced set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parallel_train_X = sc.parallelize(train_data_NotDistributed) # or use directly the train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX = parallel_train_X.map(lambda a: np.outer(a[3:], a[3:])).reduce(lambda a,b: a+b)\n",
    "yy = parallel_train_X.map(lambda a: np.outer(a[3:], a[1:3])).reduce(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 16), (16, 2))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.shape, yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = np.linalg.inv(XX).dot(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.20112332,   0.40003616],\n",
       "       [  0.07544213,   0.07243659],\n",
       "       [  6.80878733,  -1.50964233],\n",
       "       [ -3.69864834,   6.17855383],\n",
       "       [-10.68830581,  -1.12443226],\n",
       "       [  3.74523502,  -1.53292001],\n",
       "       [  0.60163843,  -6.83221707],\n",
       "       [  2.867276  ,   3.19708374],\n",
       "       [ -1.31779565,   0.45799037],\n",
       "       [  1.07483576,  -0.87620455],\n",
       "       [  1.64402582,  -1.17964847],\n",
       "       [ -7.05906705,  -7.37769584],\n",
       "       [  2.30394624,   1.89215007],\n",
       "       [  5.1616917 ,   0.78613241],\n",
       "       [  2.57448691,   5.48816121],\n",
       "       [ -3.3299369 ,   2.8900424 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.20112332,   0.40003616],\n",
       "       [  0.07544213,   0.07243659],\n",
       "       [  6.80878733,  -1.50964233],\n",
       "       [ -3.69864834,   6.17855383],\n",
       "       [-10.68830581,  -1.12443226],\n",
       "       [  3.74523502,  -1.53292001],\n",
       "       [  0.60163843,  -6.83221707],\n",
       "       [  2.867276  ,   3.19708374],\n",
       "       [ -1.31779565,   0.45799037],\n",
       "       [  1.07483576,  -0.87620455],\n",
       "       [  1.64402582,  -1.17964847],\n",
       "       [ -7.05906705,  -7.37769584],\n",
       "       [  2.30394624,   1.89215007],\n",
       "       [  5.1616917 ,   0.78613241],\n",
       "       [  2.57448691,   5.48816121],\n",
       "       [ -3.3299369 ,   2.8900424 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def solve_linear_parallel(rrd_train):\n",
    "    XX = rrd_train.map(lambda a: np.outer(a[3:], a[3:])).reduce(lambda a,b: a+b)\n",
    "    yy = rrd_train.map(lambda a: np.outer(a[3:], a[1:3])).reduce(lambda a,b: a+b)\n",
    "    W = np.linalg.inv(XX).dot(yy)\n",
    "    return W\n",
    "\n",
    "solve_linear_parallel(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on the full set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09682988,  0.0485206 ],\n",
       "       [ 0.01240669, -0.01502376],\n",
       "       [-0.14024083,  5.88192701],\n",
       "       [ 0.34187629, -3.28065969],\n",
       "       [-6.83667423,  2.31979054],\n",
       "       [ 4.59287714, -1.15516419],\n",
       "       [ 0.99581238, -5.54778859],\n",
       "       [ 1.39054027,  1.35446226],\n",
       "       [-0.867363  ,  0.33945828],\n",
       "       [ 0.69831324, -0.46888552],\n",
       "       [ 1.81161887, -2.64645593],\n",
       "       [-3.18783061, -1.90203955],\n",
       "       [ 0.22809633, -0.40600687],\n",
       "       [ 2.78471187, -0.491782  ],\n",
       "       [ 0.08956648,  4.89059757],\n",
       "       [-1.11281948,  1.72824999]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_linear_parallel(train_data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
